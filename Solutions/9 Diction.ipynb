{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Diction\n",
    "\n",
    "## Exercise 9.1\n",
    "\n",
    "Can you compare the diction of *Pride and Prejudice* using the Mann Whitney formula?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'Corpus'\n",
    "from os.path import join\n",
    "from tdmh import *\n",
    "\n",
    "corpus1 = [ 'PrideandPrejudice.txt' ]\n",
    "corpus2 = [ 'Ulysses.txt' ]\n",
    "\n",
    "\n",
    "full_text1 = ''\n",
    "full_text2 = ''\n",
    "\n",
    "for text in corpus1:\n",
    "    print('Reading ' + text + ' ... ')\n",
    "    with open( join( '..',dir,text) ) as file_handler:\n",
    "        full_text1 += file_handler.read() + ' '\n",
    "\n",
    "for text in corpus2:\n",
    "    print('Reading ' + text + ' ... ')\n",
    "    with open( join( '..',dir,text) ) as file_handler:\n",
    "        full_text2 += file_handler.read() + ' '\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "## make a list of all the words in both corpora\n",
    "words1 = tokenise_remove_stopwords(full_text1)\n",
    "words2 = tokenise_remove_stopwords(full_text2)\n",
    "\n",
    "def divide_into_chunks(words, length):\n",
    "\n",
    "    chunks=[]\n",
    "    ## chunk contains dictionaries\n",
    "    # with word frequencies\n",
    "    \n",
    "    for i in range(0, len(words), length):\n",
    "        counts = dict()\n",
    "        for j in range(length):\n",
    "            if i+j < len(words):\n",
    "                word = words[i+j]\n",
    "                counts[word] = counts.get(word,0)+1\n",
    "        chunks.append(counts)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "length = 500\n",
    "chunks1 = divide_into_chunks(words1,length)\n",
    "chunks2 = divide_into_chunks(words2,length)\n",
    "\n",
    "\n",
    "# vocab is the union of terms in both sets\n",
    "all_words = dict()\n",
    "    \n",
    "for chunk in chunks1:\n",
    "    for word in chunk:\n",
    "        all_words[word]= all_words.get(word,0) + 1\n",
    "for chunk in chunks2:\n",
    "    for word in chunk:\n",
    "        all_words[word]= all_words.get(word,0) + 1\n",
    "    \n",
    "rho =  dict()\n",
    "    \n",
    "for word in all_words:\n",
    "        \n",
    "    a=[]\n",
    "    b=[]\n",
    "        \n",
    "    for chunk in chunks1:\n",
    "        a.append(chunk.get(word,0))\n",
    "    for chunk in chunks2:\n",
    "        b.append(chunk.get(word,0))\n",
    "\n",
    "    stat,pval=mannwhitneyu(a,b, alternative=\"two-sided\")\n",
    "    mean =len(chunks1)*len(chunks2)*0.5\n",
    "    if stat <= mean:\n",
    "        pval = 0 - pval\n",
    "            \n",
    "    rho[word]= ( pval )\n",
    "    \n",
    "print( f\"\\nThe following words are most distinctive in {corpus1}\" )  \n",
    "\n",
    "i = 0\n",
    "max = 25\n",
    "\n",
    "for word in sortedByValue( rho ):\n",
    "    if rho[word] > 0:\n",
    "        print( f'{word}' ) \n",
    "        i += 1\n",
    "        if i == max:\n",
    "            break\n",
    "            \n",
    "\n",
    "print( f\"\\nThe following words are most distinctive in {corpus2}\" )  \n",
    "\n",
    "i = 0\n",
    "max = 25\n",
    "\n",
    "for word in sortedByValue( rho , ascending = False ) :\n",
    "    if rho[word] < 0:\n",
    "        print( f'{word}' ) \n",
    "        i += 1\n",
    "        if i == max:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
