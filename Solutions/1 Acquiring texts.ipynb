{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Acquiring texts\n",
    "\n",
    "## Exercise 1.1\n",
    "\n",
    "1. Download all the text files that are listed in the following dictionary. \n",
    "\n",
    "`\n",
    "    gutenberg_files = {\n",
    "    'https://www.gutenberg.org/files/98/98-0.txt' :\n",
    "        'A Tale of Two Cities',\n",
    "    'https://www.gutenberg.org/files/580/580-0.txt':\n",
    "        'The Pickwick Papers'\n",
    "   }\n",
    "`\n",
    "\n",
    "Save these files in a folder named 'Texts'. In Python, you can make new folders using the `os` package, as follows:\n",
    "\n",
    "`\n",
    "os.mkdir('Texts')\n",
    "`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import re\n",
    "from tdmh import *\n",
    "\n",
    "gutenberg_files = {\n",
    "    'https://www.gutenberg.org/files/98/98-0.txt' :\n",
    "        'A Tale of Two Cities',\n",
    "    'https://www.gutenberg.org/files/580/580-0.txt':\n",
    "        'The Pickwick Papers'\n",
    "   }\n",
    "\n",
    "dir = 'Texts'\n",
    "if not os.path.exists(dir): \n",
    "    os.mkdir(dir)\n",
    "    \n",
    "#os.mkdir(dir)\n",
    "\n",
    "\n",
    "for url in gutenberg_files:\n",
    "    print(\"Downloading \" + gutenberg_files[url] + \" ...\")\n",
    "    response = requests.get(url)\n",
    "    title = re.sub( r'\\s+' , '_' ,  gutenberg_files[url] )\n",
    "\n",
    "    if response:\n",
    "        response.encoding = 'utf-8'\n",
    "        full_text = remove_pg_boilerplate(response.text)      \n",
    "        \n",
    "        path = os.path.join( dir , f'{title}.txt' )\n",
    "        out = open( path , 'w' , encoding = 'utf-8')\n",
    "\n",
    "        out.write( full_text.strip() )\n",
    "        out.close()\n",
    "\n",
    "print('\\nDone!')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2.\n",
    "\n",
    "Potentially, you can acquire texts using Web Scraping. \n",
    "\n",
    "The webpage below offers access to the complete work of H.P. Lovecraft. \n",
    "http://www.hplovecraft.com/writings/texts/\n",
    "\n",
    "Can you write code in Python to download all the texts that are listed on this page?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "dir = 'Lovecraft'\n",
    "if not os.path.exists(dir): \n",
    "    os.mkdir(dir)\n",
    "\n",
    "baseUrl = \"http://www.hplovecraft.com/writings/texts/\"\n",
    "\n",
    "soup = \"\"\n",
    "\n",
    "response = requests.get( baseUrl )\n",
    "\n",
    "soup = BeautifulSoup( response.text ,\"lxml\")\n",
    "links = soup.find_all(\"a\")\n",
    "\n",
    "\n",
    "for l in links:\n",
    "\n",
    "    if l.get(\"href\") is not None:\n",
    "        \n",
    "        ## The body of <a> contains the title \n",
    "        if l.string is not None:\n",
    "            linktext = l.string\n",
    "        else:\n",
    "            linktext = l.get(\"href\")\n",
    "            linktext = linktext[ linktext.rindex('/') + 1 : ]\n",
    "            linktext = re.sub( r'[.]aspx' , '' , linktext )\n",
    "            \n",
    "        textUrl = baseUrl + l.get(\"href\")\n",
    "\n",
    "        if re.search( 'fiction' , textUrl ):\n",
    "            print(f\"{linktext}: {textUrl}\")\n",
    "            response = requests.get( textUrl )\n",
    "            soup = BeautifulSoup( response.text ,\"lxml\")\n",
    "            body = soup.find(\"body\")\n",
    "\n",
    "            fullText = body.get_text()\n",
    "            fullText = re.sub( 'By H. P. Lovecraft' , ' by H. P. Lovecraft ' , fullText )\n",
    "\n",
    "            fullText = fullText[fullText.index('About This Site') + 15 : ]\n",
    "            fullText = fullText[ 0 : fullText.rindex('Return to ') ]\n",
    "            fullText = fullText.strip()\n",
    "            \n",
    "            path = os.path.join( dir , linktext + '.txt' )\n",
    "\n",
    "            out = open( path , 'w' , encoding = 'utf-8' )\n",
    "            out.write( fullText )\n",
    "            out.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
